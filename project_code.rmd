---
title: "Breast Cancer and Machine Learning Prediction"
author: "Louie Sui"
date: "2022-11-10"
output: pdf_document
---

# Import Libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(caTools)
library(class)
library(rpart)
set.seed(23)
```

# Import Dataset
```{r}
cancer = read.csv("breastcancer.csv")

names(cancer) = c("Sample_ID",
                  "Clump_Thickness",
                  "Uniformity_of_Cell_Size",
                  "Uniformity_of_Cell_Shape",
                  "Marginal_Adhesion",
                  "Single_Epithelial_Cell_Size",
                  "Bare_Nuclei",
                  "Bland_Chromatin",
                  "Normal_Nucleoli",
                  "Mitoses",
                  "Class")

cancer = na.omit(cancer)
cancer$Class = factor(cancer$Class,
                      levels=c(2,4),
                      labels=c("Benign","Malignant"))
```

#### Plot scatterplot of clump thickness and cell size with the nature of the cell color-coded. 
```{r}
cancer %>%
  ggplot(aes(x=Clump_Thickness, y=Uniformity_of_Cell_Size, color = Class)) +
  geom_point()
```

# Define Functions
Sensitivity evaluates the effectiveness of a model by quantifying its capacity to accurately identify positive outcomes when they truly occur.
```{r}
sensitivity = function(cm){
  return(cm[2,2]/(cm[2,2]+cm[2,1]))
}
```

Specificity measures the quality of the model by determining its accuracy in predicting negative outcomes when the actual results of the data are indeed negative. It quantifies
the rate at which the model correctly identifies true negatives.
```{r}
specificity = function(cm){
  return(cm[1,1]/(cm[1,1]+cm[1,2]))
}
```

Accuracy evaluates the overall performance of a model by measuring the rate at which it correctly predicts both positive and negative outcomes among all instances. It provides
an assessment of the model's overall correctness in its predictions, regardless of the specific class.
```{r}
accuracy = function(cm){
  return((cm[1,1]+cm[2,2])/(cm[1,1]+cm[1,2]+cm[2,1]+cm[2,2]))
}
```

Precision quantifies the ability of a model to accurately predict positive outcomes among all the positive predictions it has made. It calculates the rate at which the model
correctly identifies true positives out of all the instances it predicted as positive. 
```{r}
precision = function(cm){
  return(cm[2,2]/(cm[2,2]+cm[1,2]))
}
```

# Clean the Data - standardizing quantitative values
```{r}
cancer$Clump_Thickness = scale(cancer$Clump_Thickness)
cancer$Uniformity_of_Cell_Size = scale(cancer$Uniformity_of_Cell_Size)
cancer$Uniformity_of_Cell_Shape = scale(cancer$Uniformity_of_Cell_Shape)
cancer$Marginal_Adhesion = scale(cancer$Marginal_Adhesion)
cancer$Single_Epithelial_Cell_Size = scale(cancer$Single_Epithelial_Cell_Size)
```

# Create Training and Test Data Sets - 67/33 split                                                                     . 
```{r}
split = sample(x=2, size=nrow(cancer), replace=TRUE, prob=c(.67, .33))
cancer.training = cancer[split==1, 2:6]
cancer.test = cancer[split==2, 2:6]
cancer.trainLabels = cancer[split==1, 11]
cancer.testLabels = cancer[split==2, 11]
```

# Technique 1 - KNN Prediction Model
```{r}
prediction = knn(train=cancer.training
                 , test=cancer.test
                 , cl=cancer.trainLabels
                 , k=3)
```

#### KNN - confusion matrix
```{r}
(confusionMatrix = table(actual=cancer.testLabels,
                        prediction))
```

#### KNN - quality
Sensitivity of this model is 0.8889
```{r}
sensitivity(confusionMatrix)
```

Specificity of this model is 0.9515
```{r}
specificity(confusionMatrix)
```

Accuracy of this model is 0.9325
```{r}
accuracy(confusionMatrix)
```

Precision of this model is 0.8889
```{r}
precision(confusionMatrix)
```

# Technique 2 - Logistic Regression Model
```{r}
trainingWithLabel = cancer.training
trainingWithLabel$class = cancer.trainLabels

logModel = glm(class ~ 
                 Clump_Thickness + 
                 Uniformity_of_Cell_Size + 
                 Uniformity_of_Cell_Shape +
                 Marginal_Adhesion +
                 Single_Epithelial_Cell_Size, 
               data=trainingWithLabel, 
               family="binomial")

predictionLog = predict(logModel, cancer.test, type="response")

cancer.test$class = cancer.testLabels
cancer.test$prediction = ifelse(predictionLog>0.7, "Malignant", "Benign")
```

#### Logistic Regression Model - confusion matrix
```{r}
(logConfusionMatrix = table(prediction=cancer.test$prediction,
                           actual=cancer.testLabels))
```

#### Logistics Regression Model - quality
Sensitivity of the logistics model is 0.9104
```{r}
sensitivity(logConfusionMatrix)
```

Specificity of the logistics model is 0.9353
```{r}
specificity(logConfusionMatrix)
```

Cccuracy of the logistics model is 0.9283
```{r}
accuracy(logConfusionMatrix)
```

Precision of the logistics model is .8472
```{r}
precision(logConfusionMatrix)
```

# Technique 3 - Decision Tree Model
```{r}
treeModel = rpart(class ~
                    Clump_Thickness +
                    Uniformity_of_Cell_Size +
                    Uniformity_of_Cell_Shape +
                    Marginal_Adhesion +
                    Single_Epithelial_Cell_Size,
                  data=trainingWithLabel,
                  control=rpart.control(maxdepth = 3),
                  method='class')

predictionTree = predict(treeModel, cancer.test, type="class")
```

####  Decision Tree - confusion matrix
```{r}
(treeConfusionMatrix = table(actual=cancer.testLabels,
                            prediction=predictionTree))
```

#### Decision Tree - quality
Sensitivity for the decision tree matrix is .9167
```{r}
sensitivity(treeConfusionMatrix)
```

Specificity of the decision tree model is .9394
```{r}
specificity(treeConfusionMatrix)
```

Accuracy of the decision tree model is .9325
```{r}
accuracy(treeConfusionMatrix)
```

Precision of the decision tree model is .8684
```{r}
precision(treeConfusionMatrix)
```
